{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b934b8b",
   "metadata": {},
   "source": [
    "#### **Model from Scratch**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1054b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0b4fe",
   "metadata": {},
   "source": [
    "#### **Training Dataset import**\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94224b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chars74kDataset(Dataset):\n",
    "    def __init__(self, root_dir, gen_transforms=None, train_transforms=None, train=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.gen_transforms = gen_transforms\n",
    "        self.train_transforms = train_transforms\n",
    "        self.train = train\n",
    "\n",
    "        self.samples = []\n",
    "        for cls in sorted(os.listdir(root_dir)):\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(cls_dir):\n",
    "                continue\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith('.png'):\n",
    "                    self.samples.append((os.path.join(cls_dir, fname), cls))\n",
    "\n",
    "        self.classes = sorted({label for img, label in self.samples})\n",
    "        self.cls2idx = {cls: idx + 1 for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, cls = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "\n",
    "        if self.gen_transforms:\n",
    "            img = self.gen_transforms(img)\n",
    "        if self.train and self.train_transforms:\n",
    "            img = self.train_transforms(img)\n",
    "\n",
    "        label = self.cls2idx[cls]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cb2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x < 0.7).float())\n",
    "])\n",
    "\n",
    "train_augment = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(0.2),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.1, 0.1),\n",
    "        scale=(0.9, 1.1)\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb0059",
   "metadata": {},
   "source": [
    "#### **Séparation des données**\n",
    "\n",
    "Pour garantir une évaluation fiable et éviter toute fuite d’information (data leakage) :\n",
    "\n",
    "* **3 ensembles distincts** :\n",
    "\n",
    "  * `train` (65 %) : apprentissage des paramètres du modèle.\n",
    "  * `val` (15 %) : réglage des hyperparamètres et choix de la meilleure version du modèle.\n",
    "  * `test` (20 %) : mesure finale de performance, à n’utiliser qu’une seule fois après la phase de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43740c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = Chars74kDataset(root_dir='C:/Users/G-PROGNOS-01/Desktop/Slomiany Baptiste/doc_lisibility/data/Chars74k/EnglishImg', gen_transforms=gen_transform,\n",
    "                               train_transforms=None, train=False)\n",
    "all_labels = np.array([full_dataset[i][1] for i in range(len(full_dataset))])\n",
    "\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "temp_idx, test_idx = next(sss1.split(np.zeros(len(all_labels)), all_labels))\n",
    "\n",
    "temp_labels = all_labels[temp_idx]\n",
    "val_size = 0.15 / 0.8\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=42)\n",
    "train_subidx, val_subidx = next(sss2.split(np.zeros(len(temp_labels)), temp_labels))\n",
    "\n",
    "train_idx = temp_idx[train_subidx]\n",
    "val_idx   = temp_idx[val_subidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7607e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Chars74kDataset(root_dir='C:/Users/G-PROGNOS-01/Desktop/Slomiany Baptiste/doc_lisibility/data/Chars74k/EnglishImg', gen_transforms=gen_transform,\n",
    "                                train_transforms=train_augment, train=True)\n",
    "train_ds = Subset(train_dataset, train_idx)\n",
    "\n",
    "val_dataset = Chars74kDataset(root_dir='C:/Users/G-PROGNOS-01/Desktop/Slomiany Baptiste/doc_lisibility/data/Chars74k/EnglishImg', gen_transforms=gen_transform,\n",
    "                              train_transforms=None, train=False)\n",
    "val_ds = Subset(val_dataset, val_idx)\n",
    "\n",
    "test_dataset = Chars74kDataset(root_dir='C:/Users/G-PROGNOS-01/Desktop/Slomiany Baptiste/doc_lisibility/data/Chars74k/EnglishImg', gen_transforms=gen_transform,\n",
    "                               train_transforms=None, train=False)\n",
    "test_ds = Subset(test_dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db34b3",
   "metadata": {},
   "source": [
    "#### **Visualisation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83208b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(string.digits + string.ascii_uppercase + string.ascii_lowercase)\n",
    "class_names = {i + 1: char for i, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a2e9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_random_chars(dataset, n_rows=2, n_cols=5, class_names=None):\n",
    "    n = n_rows * n_cols\n",
    "    indices = random.sample(range(len(dataset)), n)\n",
    "    images, labels = zip(*[dataset[i] for i in indices])\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 2*n_rows))\n",
    "\n",
    "    for ax, img, label in zip(axes.flatten(), images, labels):\n",
    "        img_np = img.squeeze().numpy()\n",
    "\n",
    "        ax.imshow(img_np, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "        ax.set_title(f\"Caractère : {class_names[label]}\")\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_chars(train_dataset, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023c39e",
   "metadata": {},
   "source": [
    "#### **Model definition and Training**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791c3d9",
   "metadata": {},
   "source": [
    "#### **Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7336aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBaselineCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(8, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_activations=False):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.features(x)\n",
    "        if log_activations:\n",
    "            activations['block1'] = x\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        if log_activations:\n",
    "            activations['logits'] = x\n",
    "            return x, activations\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f0ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train function\n",
    "def train_model( model, train_loader, val_loader, num_epochs,\n",
    "                 criterion, optimizer, writer ):\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            result = model(inputs)\n",
    "            outputs = result[0] if isinstance(result, tuple) else result ## prise en compte retour activations\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_corrects = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                result = model(inputs)\n",
    "                outputs = result[0] if isinstance(result, tuple) else result\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects / len(val_loader.dataset)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Acc/Train\", epoch_acc, epoch)\n",
    "        writer.add_scalar(\"Acc/Val\", val_acc, epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param.cpu(), epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f\"{name}_grad\", param.grad.cpu(), epoch)\n",
    "\n",
    "        images, _ = next(iter(val_loader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result = model(images, log_activations=True)\n",
    "            outputs, activations = result if isinstance(result, tuple) else (result, {})\n",
    "        for layer, activation in activations.items():\n",
    "            if activation.ndim == 4:\n",
    "                for i in range(activation.size(1)):\n",
    "                    writer.add_image(\n",
    "                        f\"Activations/{layer}/{i}\",\n",
    "                        activation[0, i].unsqueeze(0).cpu(),\n",
    "                        epoch)\n",
    "\n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f95931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 3.8652, Train Acc: 0.4109 | Val Loss: 0.9301, Val Acc: 0.7422\n",
      "Epoch 2/5 | Train Loss: 1.3318, Train Acc: 0.6337 | Val Loss: 0.7948, Val Acc: 0.7783\n",
      "Epoch 3/5 | Train Loss: 1.1681, Train Acc: 0.6726 | Val Loss: 0.7187, Val Acc: 0.7907\n",
      "Epoch 4/5 | Train Loss: 1.0789, Train Acc: 0.6935 | Val Loss: 0.7124, Val Acc: 0.7919\n",
      "Epoch 5/5 | Train Loss: 1.0174, Train Acc: 0.7067 | Val Loss: 0.6906, Val Acc: 0.7994\n"
     ]
    }
   ],
   "source": [
    "### Parametrisation\n",
    "\n",
    "cnn_model = SimpleBaselineCNN(63)\n",
    "optimizer = optim.AdamW(cnn_model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/baseline_train0\")\n",
    "epochs = 5\n",
    "\n",
    "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs, criterion, optimizer, writer)\n",
    "torch.save(cnn_model.state_dict(), \"baseline_cnn0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802d1ec",
   "metadata": {},
   "source": [
    "#### **VGGLikeNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLikeNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_activations=False):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.block1(x)\n",
    "        if log_activations:\n",
    "            activations['block1_out'] = x\n",
    "\n",
    "        x = self.block2(x)\n",
    "        if log_activations:\n",
    "            activations['block2_out'] = x\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "        if log_activations:\n",
    "            activations['logits'] = logits\n",
    "            return logits, activations\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b08f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 3.3958, Train Acc: 0.3287 | Val Loss: 0.9749, Val Acc: 0.7332\n",
      "Epoch 2/5 | Train Loss: 1.4173, Train Acc: 0.6059 | Val Loss: 0.7376, Val Acc: 0.7815\n",
      "Epoch 3/5 | Train Loss: 1.1626, Train Acc: 0.6660 | Val Loss: 0.6839, Val Acc: 0.7978\n",
      "Epoch 4/5 | Train Loss: 1.0424, Train Acc: 0.6956 | Val Loss: 0.6258, Val Acc: 0.8063\n",
      "Epoch 5/5 | Train Loss: 0.9722, Train Acc: 0.7104 | Val Loss: 0.5864, Val Acc: 0.8205\n"
     ]
    }
   ],
   "source": [
    "### Parametrisation\n",
    "\n",
    "cnn_model = VGGLikeNN(63)\n",
    "optimizer = optim.AdamW(cnn_model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/vgglike_train0\")\n",
    "epochs = 5\n",
    "\n",
    "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs, criterion, optimizer, writer)\n",
    "torch.save(cnn_model.state_dict(), \"vgglikeNet0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9abf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        Y = self.block(x)\n",
    "        X = self.link(x)\n",
    "\n",
    "        return F.max_pool2d(F.relu(Y + X), 2, 2)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.block1 = ResBlock(1, 16)\n",
    "        self.block2 = ResBlock(16, 64)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_activations=False):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.block1(x)\n",
    "        if log_activations:\n",
    "            activations['block1_out'] = x\n",
    "\n",
    "        x = self.block2(x)\n",
    "        if log_activations:\n",
    "            activations['block2_out'] = x\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "        if log_activations:\n",
    "            activations['logits'] = logits\n",
    "            return logits, activations\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d430c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 3.1577, Train Acc: 0.3299 | Val Loss: 1.0574, Val Acc: 0.7193\n",
      "Epoch 2/5 | Train Loss: 1.5774, Train Acc: 0.5675 | Val Loss: 0.9310, Val Acc: 0.7413\n",
      "Epoch 3/5 | Train Loss: 1.3598, Train Acc: 0.6214 | Val Loss: 0.8673, Val Acc: 0.7558\n",
      "Epoch 4/5 | Train Loss: 1.2340, Train Acc: 0.6520 | Val Loss: 0.7640, Val Acc: 0.7800\n",
      "Epoch 5/5 | Train Loss: 1.1660, Train Acc: 0.6657 | Val Loss: 0.7186, Val Acc: 0.7893\n"
     ]
    }
   ],
   "source": [
    "### Parametrisation\n",
    "\n",
    "cnn_model = ResNet(63)\n",
    "optimizer = optim.AdamW(cnn_model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/resnetlike_train0\")\n",
    "epochs = 5\n",
    "\n",
    "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs, criterion, optimizer, writer)\n",
    "torch.save(cnn_model.state_dict(), \"resnetlikeNet0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a35bbd",
   "metadata": {},
   "source": [
    "#### **ResNext**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58264ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResXBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels//2, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels//2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.link = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels//2, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        Y = self.block(x)\n",
    "        X = self.link(x)\n",
    "\n",
    "        return F.max_pool2d(F.relu(torch.concat([X, Y], 1)), 2, 2)\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.block1 = ResXBlock(1, 16)\n",
    "        self.block2 = ResXBlock(16, 64)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_activations=False):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.block1(x)\n",
    "        if log_activations:\n",
    "            activations['block1_out'] = x\n",
    "\n",
    "        x = self.block2(x)\n",
    "        if log_activations:\n",
    "            activations['block2_out'] = x\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "        if log_activations:\n",
    "            activations['logits'] = logits\n",
    "            return logits, activations\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd91d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 2.6790, Train Acc: 0.4299 | Val Loss: 0.9889, Val Acc: 0.7298\n",
      "Epoch 2/5 | Train Loss: 1.3757, Train Acc: 0.6210 | Val Loss: 0.8354, Val Acc: 0.7707\n",
      "Epoch 3/5 | Train Loss: 1.1906, Train Acc: 0.6683 | Val Loss: 0.7694, Val Acc: 0.7883\n",
      "Epoch 4/5 | Train Loss: 1.0919, Train Acc: 0.6907 | Val Loss: 0.7097, Val Acc: 0.8021\n",
      "Epoch 5/5 | Train Loss: 1.0316, Train Acc: 0.7044 | Val Loss: 0.6736, Val Acc: 0.8057\n"
     ]
    }
   ],
   "source": [
    "### Parametrisation\n",
    "\n",
    "cnn_model = ResNeXt(63)\n",
    "optimizer = optim.AdamW(cnn_model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/resneXtlike_train0\")\n",
    "epochs = 5\n",
    "\n",
    "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs, criterion, optimizer, writer)\n",
    "torch.save(cnn_model.state_dict(), \"resneXtlikeNet0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d514d",
   "metadata": {},
   "source": [
    "#### **InceptionBased Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced9288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 4, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, out_channels//4, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels//4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 4, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, out_channels//4, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels//4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 4, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, out_channels//4, 5, 1, 2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels//4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 4, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, out_channels//4, 7, 1, 3, bias=False),\n",
    "            nn.BatchNorm2d(out_channels//4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        Y1 = self.block1(x)\n",
    "        Y2 = self.block2(x)\n",
    "        Y3 = self.block3(x)\n",
    "        Y4 = self.block4(x)\n",
    "\n",
    "        return F.max_pool2d(F.relu(torch.concat([Y1, Y2, Y3, Y4], 1)), 2, 2)\n",
    "\n",
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.block1 = InceptionBlock(1, 16)\n",
    "        self.block2 = InceptionBlock(16, 64)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_activations=False):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.block1(x)\n",
    "        if log_activations:\n",
    "            activations['block1_out'] = x\n",
    "\n",
    "        x = self.block2(x)\n",
    "        if log_activations:\n",
    "            activations['block2_out'] = x\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "        if log_activations:\n",
    "            activations['logits'] = logits\n",
    "            return logits, activations\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f091cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 3.5310, Train Acc: 0.3934 | Val Loss: 0.9814, Val Acc: 0.7353\n",
      "Epoch 2/5 | Train Loss: 1.2768, Train Acc: 0.6398 | Val Loss: 0.7537, Val Acc: 0.7798\n",
      "Epoch 3/5 | Train Loss: 1.0932, Train Acc: 0.6860 | Val Loss: 0.7813, Val Acc: 0.7638\n",
      "Epoch 4/5 | Train Loss: 1.0023, Train Acc: 0.7073 | Val Loss: 0.6858, Val Acc: 0.7951\n",
      "Epoch 5/5 | Train Loss: 0.9505, Train Acc: 0.7168 | Val Loss: 0.6577, Val Acc: 0.7949\n"
     ]
    }
   ],
   "source": [
    "### Parametrisation\n",
    "\n",
    "cnn_model = InceptionNet(63)\n",
    "optimizer = optim.AdamW(cnn_model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/InceptionNetlike_train0\")\n",
    "epochs = 5\n",
    "\n",
    "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs, criterion, optimizer, writer)\n",
    "torch.save(cnn_model.state_dict(), \"InceptionNet0.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
