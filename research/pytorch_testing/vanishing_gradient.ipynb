{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b934b8b",
   "metadata": {},
   "source": [
    "#### **Vanishing Gradient with Sigmoid**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1054b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f89d71",
   "metadata": {},
   "source": [
    "#### Import jeu de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e48913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chars74kDataset(Dataset):\n",
    "    def __init__(self, root_dir, transforms=None):\n",
    "        self.samples = []\n",
    "        self.transforms = transforms\n",
    "        for cls in sorted(os.listdir(root_dir)):\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            if os.path.isdir(cls_dir):\n",
    "                for fname in os.listdir(cls_dir):\n",
    "                    if fname.lower().endswith('.png'):\n",
    "                        self.samples.append((os.path.join(cls_dir, fname), cls))\n",
    "        self.classes = sorted({label for _, label in self.samples})\n",
    "        self.cls2idx = {cls: (idx+1) for idx, cls in enumerate(self.classes)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        path, cls = self.samples[i]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        label = self.cls2idx[cls]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8272219",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x < 0.7).float())\n",
    "])\n",
    "\n",
    "dataset = Chars74kDataset('data/Chars74k/EnglishImg', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a96738a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "all_indices = np.arange(len(dataset))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "val_idx   = all_indices[:n_val]\n",
    "train_idx = all_indices[n_val:]\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db34b3",
   "metadata": {},
   "source": [
    "#### **Visualisation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83208b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(string.digits + string.ascii_uppercase + string.ascii_lowercase)\n",
    "class_names = {i + 1: char for i, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a2e9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1750x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_random_chars(dataset, n_rows=2, n_cols=5, class_names=None):\n",
    "    n = n_rows * n_cols\n",
    "    indices = random.sample(range(len(dataset)), n)\n",
    "    images, labels = zip(*[dataset[i] for i in indices])\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 2.5*n_rows))\n",
    "\n",
    "    for ax, img, label in zip(axes.flatten(), images, labels):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_np = img.squeeze().numpy()\n",
    "        else:\n",
    "            img_np = img\n",
    "        ax.imshow(img_np, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        if class_names:\n",
    "            ax.set_title(f\"Caracter : {class_names[label]}\")\n",
    "        else:\n",
    "            ax.set_title(f'Label: {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_chars(dataset, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023c39e",
   "metadata": {},
   "source": [
    "#### **Model definition and Training**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLikeNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Bloc 1\n",
    "        self.conv1_1 = nn.Conv2d(1, 2, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(2, 4, kernel_size=3, padding=1)\n",
    "        self.sigmoid1_1 = nn.Sigmoid()\n",
    "        self.pool1   = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bloc 2\n",
    "        self.conv2_1 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.sigmoid2_1 = nn.Sigmoid()\n",
    "        self.pool2   = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Classifieur\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1     = nn.Linear(16 * 7 * 7, 256)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2     = nn.Linear(256, 128)\n",
    "        self.out     = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = {}\n",
    "\n",
    "        x = self.conv1_1(x); activations['conv1_1'] = x\n",
    "        x = self.conv1_2(x); activations['conv1_2'] = x\n",
    "        x = self.sigmoid1_1(x); activations['sigmoid1_1'] = x\n",
    "        x = self.pool1(x);   activations['pool1']   = x\n",
    "\n",
    "        x = self.conv2_1(x); activations['conv2_1'] = x\n",
    "        x = self.conv2_2(x); activations['conv2_2'] = x\n",
    "        x = self.sigmoid2_1(x); activations['sigmoid2_1'] = x\n",
    "        x = self.pool2(x);   activations['pool2']   = x\n",
    "\n",
    "        x = self.flatten(x);         activations['flatten'] = x\n",
    "        x = self.fc1(x);             activations['fc1']     = x\n",
    "        x = self.relu_fc(x);         activations['relu_fc1']= x\n",
    "        x = self.fc2(x);             activations['fc2']     = x\n",
    "        x = self.relu_fc(x);         activations['relu_fc2']= x\n",
    "        logits = self.out(x);        activations['out']     = logits\n",
    "\n",
    "        return logits, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd91532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | train_loss: 4.1314 ‚Äî train_acc: 0.0166 | val_loss:   4.1314 ‚Äî val_acc:   0.0131\n",
      "Epoch 10/30 | train_loss: 4.1288 ‚Äî train_acc: 0.0164 | val_loss:   4.1289 ‚Äî val_acc:   0.0131\n",
      "Epoch 15/30 | train_loss: 4.1283 ‚Äî train_acc: 0.0160 | val_loss:   4.1289 ‚Äî val_acc:   0.0131\n",
      "Epoch 20/30 | train_loss: 4.1283 ‚Äî train_acc: 0.0157 | val_loss:   4.1284 ‚Äî val_acc:   0.0151\n",
      "Epoch 25/30 | train_loss: 4.1282 ‚Äî train_acc: 0.0166 | val_loss:   4.1286 ‚Äî val_acc:   0.0149\n",
      "Epoch 30/30 | train_loss: 4.1282 ‚Äî train_acc: 0.0165 | val_loss:   4.1285 ‚Äî val_acc:   0.0148\n"
     ]
    }
   ],
   "source": [
    "## Parametrisation\n",
    "\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model  = VGGLikeNN(63).to(device)\n",
    "optimizer  = optim.SGD(cnn_model.parameters(), lr=8e-3)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/mon_model_cnn_sigmoid1\")\n",
    "epochs     = 30\n",
    "\n",
    "## Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    cnn_model.train()\n",
    "    train_loss, correct = 0.0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, activations = cnn_model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc  = correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    cnn_model.eval()\n",
    "    val_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits, _ = cnn_model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc  = correct        / len(val_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"train_loss: {train_loss:.4f} ‚Äî train_acc: {train_acc:.4f} | \"\n",
    "            f\"val_loss:   {val_loss:.4f} ‚Äî val_acc:   {val_acc:.4f}\")\n",
    "\n",
    "    # Test Tensorboard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Val\",   val_loss,   epoch)\n",
    "    writer.add_scalar(\"Acc/Train\",  train_acc,  epoch)\n",
    "    writer.add_scalar(\"Acc/Val\",    val_acc,    epoch)\n",
    "\n",
    "    for name, param in cnn_model.named_parameters():\n",
    "        writer.add_histogram(name, param.cpu(), epoch)\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f\"{name}_grad\", param.grad.cpu(), epoch)\n",
    "\n",
    "    imgs, _ = next(iter(val_loader))\n",
    "    imgs = imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, activations = cnn_model(imgs)\n",
    "\n",
    "    for layer_name, activation in activations.items():\n",
    "        if activation.ndim == 4:\n",
    "            featmap = activation[0]\n",
    "            n_maps  = featmap.size(0)\n",
    "            for i in range(n_maps):\n",
    "                img_tensor = featmap[i].unsqueeze(0).cpu()\n",
    "                writer.add_image(\n",
    "                    f\"Activations/{layer_name}/map_{i}\",\n",
    "                    img_tensor,\n",
    "                    epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5722f1",
   "metadata": {},
   "source": [
    "- *Suivi des m√©triques* : le mod√®le n‚Äôapprend pas du tout  \n",
    "- *Confirmation via TensorBoard* : les poids des couches profondes restent fig√©s  \n",
    "- *Analyse des gradients* : ces couches souffrent d‚Äôune disparition de gradient, d‚Äôo√π l‚Äôabsence de mise √† jour des param√®tres  \n",
    "- *Origine du probl√®me* : la d√©riv√©e de la fonction sigmo√Øde devenant quasi nulle lorsque les activations ne sont pas normalis√©es  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8e0d5",
   "metadata": {},
   "source": [
    "#### **Avec batchNorm2d**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca3d028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLikeNN2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Bloc 1\n",
    "        self.conv1_1 = nn.Conv2d(1, 2, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(2, 4, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(4)\n",
    "        self.sigmoid1_1 = nn.Sigmoid()\n",
    "        self.pool1   = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bloc 2\n",
    "        self.conv2_1 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.sigmoid2_1 = nn.Sigmoid()\n",
    "        self.pool2   = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Classifieur\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1     = nn.Linear(16 * 7 * 7, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.relu_fc = nn.ReLU(inplace=True)\n",
    "        self.fc2     = nn.Linear(256, 128)\n",
    "        self.out     = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = {}\n",
    "\n",
    "        # --- Bloc 1 ---\n",
    "        x = self.conv1_1(x); activations['conv1_1'] = x\n",
    "        x = self.conv1_2(x); activations['conv1_2'] = x\n",
    "        x = self.bn1(x); activations['bn1'] = x\n",
    "        x = self.sigmoid1_1(x); activations['sigmoid1_1'] = x\n",
    "        x = self.pool1(x);   activations['pool1']   = x\n",
    "\n",
    "        # --- Bloc 2 ---\n",
    "        x = self.conv2_1(x); activations['conv2_1'] = x\n",
    "        x = self.conv2_2(x); activations['conv2_2'] = x\n",
    "        x = self.bn2(x); activations['bn2'] = x\n",
    "        x = self.sigmoid2_1(x); activations['sigmoid2_1'] = x\n",
    "        x = self.pool2(x);   activations['pool2']   = x\n",
    "\n",
    "        # --- Classifieur ---\n",
    "        x = self.flatten(x);         activations['flatten'] = x\n",
    "        x = self.fc1(x);             activations['fc1']     = x\n",
    "        x = self.bn3(x); activations['bn3'] = x\n",
    "        x = self.relu_fc(x);         activations['relu_fc1']= x\n",
    "        x = self.fc2(x);             activations['fc2']     = x\n",
    "        x = self.relu_fc(x);         activations['relu_fc2']= x\n",
    "        logits = self.out(x);        activations['out']     = logits\n",
    "\n",
    "        return logits, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | train_loss: 0.9085 ‚Äî train_acc: 0.7795 | val_loss:   0.8643 ‚Äî val_acc:   0.7780\n",
      "Epoch 10/30 | train_loss: 0.6097 ‚Äî train_acc: 0.8240 | val_loss:   0.6347 ‚Äî val_acc:   0.8150\n",
      "Epoch 15/30 | train_loss: 0.5069 ‚Äî train_acc: 0.8449 | val_loss:   0.5573 ‚Äî val_acc:   0.8270\n",
      "Epoch 20/30 | train_loss: 0.4429 ‚Äî train_acc: 0.8606 | val_loss:   0.5154 ‚Äî val_acc:   0.8339\n",
      "Epoch 25/30 | train_loss: 0.3956 ‚Äî train_acc: 0.8731 | val_loss:   0.4673 ‚Äî val_acc:   0.8464\n",
      "Epoch 30/30 | train_loss: 0.3569 ‚Äî train_acc: 0.8849 | val_loss:   0.4630 ‚Äî val_acc:   0.8497\n"
     ]
    }
   ],
   "source": [
    "## TODO: Training loop as function\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model  = VGGLikeNN2(63).to(device)\n",
    "optimizer  = optim.SGD(cnn_model.parameters(), lr=8e-3)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"runs/mon_model_cnn_sigmoid2_batchnormed\")\n",
    "epochs     = 30\n",
    "\n",
    "## Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    cnn_model.train()\n",
    "    train_loss, correct = 0.0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, activations = cnn_model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc  = correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    cnn_model.eval()\n",
    "    val_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits, _ = cnn_model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc  = correct        / len(val_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"train_loss: {train_loss:.4f} ‚Äî train_acc: {train_acc:.4f} | \"\n",
    "            f\"val_loss:   {val_loss:.4f} ‚Äî val_acc:   {val_acc:.4f}\")\n",
    "\n",
    "    # Test Tensorboard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Val\",   val_loss,   epoch)\n",
    "    writer.add_scalar(\"Acc/Train\",  train_acc,  epoch)\n",
    "    writer.add_scalar(\"Acc/Val\",    val_acc,    epoch)\n",
    "\n",
    "    for name, param in cnn_model.named_parameters():\n",
    "        writer.add_histogram(name, param.cpu(), epoch)\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f\"{name}_grad\", param.grad.cpu(), epoch)\n",
    "\n",
    "    imgs, _ = next(iter(val_loader))\n",
    "    imgs = imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, activations = cnn_model(imgs)\n",
    "\n",
    "    for layer_name, activation in activations.items():\n",
    "        if activation.ndim == 4:\n",
    "            featmap = activation[0]\n",
    "            n_maps  = featmap.size(0)\n",
    "            for i in range(n_maps):\n",
    "                img_tensor = featmap[i].unsqueeze(0).cpu()\n",
    "                writer.add_image(\n",
    "                    f\"Activations/{layer_name}/map_{i}\",\n",
    "                    img_tensor,\n",
    "                    epoch)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
